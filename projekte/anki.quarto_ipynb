{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "format: html\n",
        "title: Webscraping\n",
        "subtitle: Profile mit Photos der Mitarbeitenden IS1\n",
        "code-fold: true\n",
        "---\n",
        "\n",
        "\n",
        "1. Downloade [anki_webscraping.py](anki_webscraping.py)\n",
        "2. \n"
      ],
      "id": "bb0404c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# Base URL\n",
        "BASE_URL = \"https://www.phbern.ch\"\n",
        "START_URL = \"https://www.phbern.ch/ueber-die-phbern/personen?f%5B0%5D=institut%3A895\"\n",
        "\n",
        "def scrape_phbern_profiles():\n",
        "    page = 0\n",
        "    results = []\n",
        "    visited_urls = set()\n",
        "\n",
        "    while True:\n",
        "        print(f\"Scraping page {page + 1}...\")\n",
        "        url = f\"{START_URL}&page={page}\"\n",
        "        response = requests.get(url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(\"Error fetching page\", response.status_code)\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find profile links and names\n",
        "        profiles = soup.select('a[href^=\"/ueber-die-phbern/personen/\"]')\n",
        "        if not profiles:\n",
        "            print(\"No more profiles found. Exiting.\")\n",
        "            break\n",
        "\n",
        "        for profile in profiles:\n",
        "            # Clean up the name to remove excessive spaces\n",
        "            name = \" \".join(profile.text.strip().split()).strip()\n",
        "            href = profile.get('href')\n",
        "            if href and name:\n",
        "                full_url = f\"{BASE_URL}{href}\"\n",
        "                if full_url not in visited_urls:\n",
        "                    visited_urls.add(full_url)\n",
        "\n",
        "                    # Check for an image on the profile page\n",
        "                    image_url = None\n",
        "                    profile_response = requests.get(full_url)\n",
        "                    if profile_response.status_code == 200:\n",
        "                        profile_soup = BeautifulSoup(profile_response.text, 'html.parser')\n",
        "                        image = profile_soup.select_one('img[src^=\"/sites/default/files/\"]')\n",
        "                        if image:\n",
        "                            image_url = f\"<img src=\\\"{BASE_URL}{image['src']}\\\">\"\n",
        "\n",
        "                    # Only add profiles that have an image\n",
        "                    if image_url:\n",
        "                        results.append({\"name\": name, \"image_url\": image_url})\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    profiles = scrape_phbern_profiles()\n",
        "\n",
        "    # Save or print the results\n",
        "    with open(\"phbern_profiles.csv\", \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "        for profile in profiles:\n",
        "            csvwriter.writerow([profile['image_url'], profile['name']])\n",
        "\n",
        "    print(f\"Scraped {len(profiles)} profiles with images and saved to phbern_profiles.csv.\")"
      ],
      "id": "f6fe10a2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}